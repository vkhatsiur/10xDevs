# Database Plan - 10xCards

## Overview

This document defines the database schema for 10xCards MVP based on the 10xDevs course approach. The application uses PostgreSQL via Supabase with Row Level Security (RLS) to be enabled in Module 3.

## Design Principles

- **Simplicity first**: Keep schema simple for MVP
- **Performance**: Use BIGSERIAL for high-frequency tables (flashcards, generations)
- **Type safety**: Use appropriate PostgreSQL types
- **Referential integrity**: Use foreign keys with proper constraints
- **Timestamps**: Track created_at and updated_at where needed
- **Efficient storage**: Hash source text instead of storing it directly
- **Error tracking**: Log generation errors for debugging and monitoring

---

## Tables

### 1. users

**Purpose**: Store user information (managed by Supabase Auth)

**Columns**:
| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | uuid | PRIMARY KEY | User unique identifier (from Supabase Auth) |
| email | varchar(255) | UNIQUE, NOT NULL | User email address |
| encrypted_password | varchar | NOT NULL | Encrypted password (managed by Supabase Auth) |
| created_at | timestamptz | NOT NULL, DEFAULT now() | Account creation timestamp |
| confirmed_at | timestamptz | NULLABLE | Email confirmation timestamp |

**Indexes**:

- PRIMARY KEY on `id`
- UNIQUE INDEX on `email`

**Notes**:

- Managed by Supabase Auth
- For MVP, we'll create test users manually in Supabase Studio
- Password encryption handled by Supabase Auth

---

### 2. flashcards

**Purpose**: Store individual flashcards (generated or manual)

**Columns**:
| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | bigserial | PRIMARY KEY | Flashcard unique identifier |
| front | varchar(200) | NOT NULL | Flashcard front side (question) |
| back | varchar(500) | NOT NULL | Flashcard back side (answer) |
| source | varchar | NOT NULL, CHECK (source IN ('ai-full', 'ai-edited', 'manual')) | Origin of the flashcard |
| created_at | timestamptz | NOT NULL, DEFAULT now() | When flashcard was created |
| updated_at | timestamptz | NOT NULL, DEFAULT now() | Last modification timestamp |
| generation_id | bigint | NULLABLE, REFERENCES generations(id) ON DELETE SET NULL | Parent generation (if AI-generated) |
| user_id | uuid | NOT NULL, REFERENCES users(id) | Owner of this flashcard |

**Indexes**:

- PRIMARY KEY on `id`
- INDEX on `user_id` (for fetching user's flashcards)
- INDEX on `generation_id` (for fetching cards from generation)

**Foreign Keys**:

- `user_id` → `users(id)` ON DELETE CASCADE
- `generation_id` → `generations(id)` ON DELETE SET NULL
  - When generation is deleted, flashcards remain but lose reference

**Triggers**:

- `updated_at` trigger: Automatically update timestamp on row modification

**Source field values**:

- `'ai-full'`: Generated by AI, not edited by user
- `'ai-edited'`: Generated by AI, then edited by user
- `'manual'`: Created manually by user

**Notes**:

- Uses BIGSERIAL for better performance (more inserts/selects)
- `front` and `back` are more universal than `question` and `answer`
- Length constraints (200/500) are at DB level for data integrity
- `source` field helps track AI effectiveness
- Can exist without generation_id (manual cards)

---

### 3. generations

**Purpose**: Track AI generation sessions and statistics

**Columns**:
| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | bigserial | PRIMARY KEY | Generation unique identifier |
| user_id | uuid | NOT NULL, REFERENCES users(id) | User who requested generation |
| model | varchar | NOT NULL | AI model used (e.g., 'gpt-4o-mini') |
| generated_count | integer | NOT NULL | Number of flashcards generated |
| accepted_unedited_count | integer | NULLABLE | Cards accepted without edits |
| accepted_edited_count | integer | NULLABLE | Cards accepted after edits |
| source_text_hash | varchar | NOT NULL | SHA-256 hash of source text |
| source_text_length | integer | NOT NULL, CHECK (source_text_length BETWEEN 1000 AND 10000) | Length of source text |
| generation_duration | integer | NOT NULL | Generation time in milliseconds |
| created_at | timestamptz | NOT NULL, DEFAULT now() | When generation was created |
| updated_at | timestamptz | NOT NULL, DEFAULT now() | Last modification timestamp |

**Indexes**:

- PRIMARY KEY on `id`
- INDEX on `user_id` (for user's generation history)

**Foreign Keys**:

- `user_id` → `users(id)` ON DELETE CASCADE

**Notes**:

- Uses BIGSERIAL for performance
- Does NOT store actual source_text (privacy + storage efficiency)
- `source_text_hash` prevents duplicate processing
- Statistics fields (`accepted_*_count`) populated later in workflow
- `generation_duration` helps monitor AI performance
- Length constraint (1000-10000) enforced at DB level

---

### 4. generation_error_logs

**Purpose**: Log AI generation failures for debugging and monitoring

**Columns**:
| Column | Type | Constraints | Description |
|--------|------|-------------|-------------|
| id | bigserial | PRIMARY KEY | Log entry unique identifier |
| user_id | uuid | NOT NULL, REFERENCES users(id) | User who attempted generation |
| model | varchar | NOT NULL | AI model that failed |
| source_text_hash | varchar | NOT NULL | Hash of source text that failed |
| source_text_length | integer | NOT NULL, CHECK (source_text_length BETWEEN 1000 AND 10000) | Length of source text |
| error_code | varchar(100) | NOT NULL | Error code from API |
| error_message | text | NOT NULL | Detailed error message |
| created_at | timestamptz | NOT NULL, DEFAULT now() | When error occurred |

**Indexes**:

- PRIMARY KEY on `id`
- INDEX on `user_id` (for user-specific error analysis)
- INDEX on `created_at` (for time-based queries)

**Foreign Keys**:

- `user_id` → `users(id)` ON DELETE CASCADE

**Notes**:

- Helps debug AI integration issues
- Can identify problematic text patterns
- Useful for monitoring API reliability
- Does NOT store actual error-causing text (privacy)

---

## Relationships Diagram

```
users (1) ──< flashcards (many)
              │
              ├──> generations (many, optional reference)
              │
users (1) ──< generations (many)
              │
users (1) ──< generation_error_logs (many)
```

**Relationship descriptions**:

- One user can have many flashcards
- One user can have many generations
- One user can have many error logs
- One flashcard optionally references one generation
- Flashcards can exist without generation (manual creation)

---

## Data Flow

### Creating Generation (AI):

```
1. User inputs text
2. Hash source text (SHA-256)
3. Check if hash exists (avoid duplicates)
4. Call AI API with source text
5. On SUCCESS:
   a. Create generation record (hash, length, model, duration, count)
   b. Create flashcard records (front, back, source='ai-full', generation_id)
   c. Update acceptance counts (initially NULL)
6. On ERROR:
   a. Create generation_error_log record
   b. Return error to user
7. Return flashcards to client
```

### Editing AI Flashcard:

```
1. User edits front/back
2. API updates flashcard record
3. Set source = 'ai-edited'
4. updated_at is automatically set by trigger
5. Optionally update accepted_edited_count in generation
6. Return updated flashcard to client
```

### Creating Manual Flashcard:

```
1. User creates flashcard manually
2. API creates flashcard record (source='manual', generation_id=NULL)
3. Return flashcard to client
```

### Deleting Generation:

```
1. User deletes generation
2. SET NULL on all flashcards.generation_id (flashcards remain)
3. Return success to client
```

---

## PostgreSQL Features Used

### Timestamp Trigger for updated_at:

```sql
CREATE OR REPLACE FUNCTION trigger_set_timestamp()
RETURNS TRIGGER AS $$
BEGIN
  NEW.updated_at = NOW();
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER set_timestamp_flashcards
BEFORE UPDATE ON flashcards
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();

CREATE TRIGGER set_timestamp_generations
BEFORE UPDATE ON generations
FOR EACH ROW
EXECUTE FUNCTION trigger_set_timestamp();
```

### Source Text Hashing (Application Layer):

```typescript
import { createHash } from 'crypto';

function hashSourceText(text: string): string {
  return createHash('sha256').update(text).digest('hex');
}
```

---

## Row Level Security (RLS)

**Note**: RLS will be implemented in Module 3 with authentication.

**Planned policies**:

```sql
-- Flashcards: Users can only access their own
CREATE POLICY "Users can view own flashcards"
ON flashcards FOR SELECT
USING (auth.uid() = user_id);

CREATE POLICY "Users can insert own flashcards"
ON flashcards FOR INSERT
WITH CHECK (auth.uid() = user_id);

CREATE POLICY "Users can update own flashcards"
ON flashcards FOR UPDATE
USING (auth.uid() = user_id);

CREATE POLICY "Users can delete own flashcards"
ON flashcards FOR DELETE
USING (auth.uid() = user_id);

-- Similar policies for generations and generation_error_logs
```

---

## Sample Data

### Test User (created by Supabase Auth):

```sql
-- Will be created through Supabase Studio or Auth API
-- For testing, use Supabase Studio "Authentication > Users > Add user"
```

### Sample Generation:

```sql
INSERT INTO generations (user_id, model, generated_count, source_text_hash, source_text_length, generation_duration) VALUES
('<user-uuid-from-supabase>',
 'gpt-4o-mini',
 3,
 'a3c5f8e9d1b2c4a6e8f0d2b4c6a8e0f2d4b6c8a0e2f4d6b8c0a2e4f6d8b0c2a4',
 2500,
 3500);
```

### Sample Flashcards:

```sql
INSERT INTO flashcards (user_id, front, back, source, generation_id) VALUES
('<user-uuid>',
 'What is TypeScript?',
 'A strongly typed programming language that builds on JavaScript',
 'ai-full',
 1);
```

---

## Migration Strategy

### Initial Migration (20251117_init_schema.sql):

1. Create users table (basic structure, Supabase Auth manages it)
2. Create flashcards table
3. Create generations table
4. Create generation_error_logs table
5. Create updated_at trigger function
6. Apply triggers to flashcards and generations
7. Add all indexes
8. Add CHECK constraints

### Future Migrations:

- Add RLS policies (Module 3)
- Add full-text search on flashcards.front and flashcards.back
- Add materialized views for statistics
- Add indexes based on usage patterns

---

## Performance Considerations

### For MVP:

- **Expected load**: Single user, < 100 generations, < 1000 flashcards
- BIGSERIAL more efficient than UUID for high-frequency inserts
- Hashing source text reduces storage significantly

### For Future:

- Consider partitioning generation_error_logs by month
- Add partial indexes for active flashcards
- Consider full-text search indexes (GIN)
- Add materialized view for user statistics

---

## Security Considerations

### MVP:

- No RLS (single test user)
- Input validation in API layer
- SQL injection prevention via parameterized queries
- Source text not stored (privacy)

### Module 3:

- Enable RLS on all tables
- Implement authentication with Supabase Auth
- Add policies for user data isolation
- Ensure error logs don't expose sensitive data

---

## Validation Rules

**Application-level validation** (API layer):

### Source Text:

- Min: 1000 characters
- Max: 10000 characters
- Hash before storing

### Flashcards:

- `front`: min 1 char, max 200 chars
- `back`: min 1 char, max 500 chars
- `source`: must be one of enum values
- `user_id`: must exist in users table

### Generations:

- `model`: must be valid model identifier
- `generated_count`: must match actual flashcard count
- `generation_duration`: must be > 0

**Note**: Length constraints ARE enforced at DB level for data integrity.

---

## Type Generation

After migrations, generate TypeScript types:

```bash
npm run db:types
```

This creates `src/db/types.ts` with:

```typescript
export type Database = {
  public: {
    Tables: {
      flashcards: {
        Row: {
          id: number;
          front: string;
          back: string;
          source: 'ai-full' | 'ai-edited' | 'manual';
          created_at: string;
          updated_at: string;
          generation_id: number | null;
          user_id: string;
        };
        Insert: {
          /* ... */
        };
        Update: {
          /* ... */
        };
      };
      // ... other tables
    };
  };
};
```

---

## Analytics & Insights

### Useful Queries:

**AI Effectiveness**:

```sql
SELECT
  COUNT(*) FILTER (WHERE source = 'ai-full') as unedited,
  COUNT(*) FILTER (WHERE source = 'ai-edited') as edited,
  COUNT(*) FILTER (WHERE source = 'manual') as manual
FROM flashcards
WHERE user_id = '<user-uuid>';
```

**Error Rate by Model**:

```sql
SELECT
  model,
  COUNT(*) as error_count,
  AVG(source_text_length) as avg_text_length
FROM generation_error_logs
WHERE created_at > NOW() - INTERVAL '7 days'
GROUP BY model;
```

**Average Generation Time**:

```sql
SELECT
  model,
  AVG(generation_duration) as avg_duration_ms,
  AVG(generated_count) as avg_cards_per_gen
FROM generations
GROUP BY model;
```

---

## Summary

This database schema provides:

- ✅ Efficient storage with BIGSERIAL and hashing
- ✅ Comprehensive error logging
- ✅ AI effectiveness tracking (source field)
- ✅ Performance statistics (duration, counts)
- ✅ Clean separation of concerns
- ✅ Privacy-conscious (no source text storage)
- ✅ Future-proof structure (ready for auth and analytics)

**Key differences from initial plan**:

- BIGSERIAL instead of UUID for performance
- `front`/`back` instead of `question`/`answer` (more universal)
- Added `source` field to track AI effectiveness
- Hash source text instead of storing it (privacy + efficiency)
- Added comprehensive generation statistics
- Added error logging table
- Removed study_sessions (not needed for MVP)

**Next steps**:

1. Create migration file with this schema
2. Run migration: `npm run db:start` then `npm run db:reset`
3. Verify in Supabase Studio (http://localhost:54323)
4. Generate TypeScript types: `npm run db:types`
5. Start building API layer

---

**Document Version**: 2.0
**Last Updated**: 2025-11-17
**Status**: Ready for implementation
